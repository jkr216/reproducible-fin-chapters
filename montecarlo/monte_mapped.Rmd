---
title: "Monte Carlo Chapter"
output:
     pdf_document:
         latex_engine: xelatex
---

```{r setup, include = FALSE}
library(tidyquant)
library(tidyverse)
library(highcharter)
library(scales)
knitr::opts_chunk$set(message=FALSE, warning=FALSE)
load("~/reproducible-fin-chapters/returns/book-data.Rdata")
```

Let's wrap things up by having some fun, which means simulating returns out into the future.  

We will revisit these steps in more detail below but briefly we will: 

1) Assume our returns are normally distributed
2) Assume that normal distribution is described by the mean and standard deviation previously calculated
3) Write several equivalent functions to run simulations based on the mean and standard deviation
4) Choose a number of months to simulate and the number of times to run the simulation
5) Write a code flow to run our functions for the chosen months and simulations
6) Visualize our results

The first step is a crucial one and it bears a bit more discussion.  We make an assumption that the distribution of portfolio returns are normal.  We have done plenty of visualizing of those returns and examined the skewness and kurtosis to see to what extent the returns are not normal. Is the assumption correct? Are the returns normally distributed? For our purposes, we will say yes - but the empirical question of whether we are right or wrong is not the focus of this book. Rather, the more important point for making our work reproducible is to explicitly declare this assumption, explain where it came from (our work on portfolio returns) and discuss any weaknesses (maybe high skewness or kurtosis which we have already discussed).  The goal is for a team member or end consumer to understand the assumption, be able to reproduce any evidence for or against it, and decide independently if the assumption is valid enough to support our simulation.  

First, we need to define our mean and standard deviation.

```{r}
mean_port_return <- mean(portfolio_returns_tq_rebalanced_monthly$returns)
stddev_port_return <- sd(portfolio_returns_tq_rebalanced_monthly$returns)
```


Next we use the `rnorm()` function to sample from a distribution with mean equal to `mean_port_return` and standard deviation equal to `stddev_port_return`.  How many times should we draw from this distribution, meaning how many monthly returns should we simulate? We are using monthly returns and 120 months is 10 years - that feels like a good amount of time to simulate. Again, perhaps you or anyone thinks that simulating returns in this way is a bad idea. Please feel free to use a different method for generating theoretical future returns!

```{r}
simulated_monthly_returns <- rnorm(120, mean_port_return, stddev_port_return)
```

Have a quick look at the simulated monthly returns. 

```{r}
head(simulated_monthly_returns)
tail(simulated_monthly_returns)
```

Hard to get an intution about whether these results make sense. Let's calculate the growth of a dollar using that `simulated_monthly_returns` object.  This is very similar to how we calculated the growth of a dollar in our actual portfolio in Section 1. We add a 1 to each of our monthly returns and then run cumulative functions.

```{r}
simulated_returns_add_1 <- 
  tibble(c(1, 1 + simulated_monthly_returns)) %>% 
  `colnames<-`("returns")

head(simulated_returns_add_1)
```

That object is now ready to be converted into the cumulative growth of a dollar. We can use either `accumulate()` from `purrr` or `cumprod()`. Let's use both of them and confirm consistent, reasonable results. 

```{r}

simulated_growth <- 
simulated_returns_add_1 %>%
    mutate(growth1 = accumulate(returns, function(x, y) x * y),
           growth2 = accumulate(returns, `*`),
           growth3 = cumprod(returns)) %>% 
    select(-returns)

tail(simulated_growth)
```

The results are consistent. 

Are they reasonable? Let's check out the compound annual growth rate that is implied by this simulation.

```{r}
cagr <- ((simulated_growth$growth1[nrow(simulated_growth)] ^ (1/10)) -1) * 100
cagr
```


This simulation indicates our portfolio grew in size to `r simulated_growth$growth1[nrow(simulated_growth)]` over the simulated future 10 years, implying an annual compounded growth of `r cagr`%. That seems reasonable given our actual returns have all been taken from a raging bull market. Remember, it's a simulation. If you re run this code on your own, you will get a different result each time.

If we feel good about this first simulation, we now want to run a lot more of them to get a sense for how they are distributed.

First, we will build simulation functions that incorporate the `accumulate()` and `cumprod()` workflows above. We have confirmed they give consistent results so it's a matter of aesthetics as to which one is chosen in the end. Perhaps you feel that one is more flexible or extensible or fits better with your team's code flows.

Each function needs 4 arguments: N for the number of months to simulate (we chose 120 above), init_value for the starting value (we used $1 above) and the mean/standard deviation pair to create draws from a normal distribution. We choose N and init_value, and derive the mean/sd pair from our portfolio monthly returns object. 

Here is our first growth simulation function using `accumulate()`

```{r}

simulation_accum_1 <- function(init_value, N, mean, stdev) {
    tibble(c(init_value, 1 + rnorm(N, mean, stdev))) %>% 
    `colnames<-`("returns") %>%
    mutate(growth = accumulate(returns, function(x, y) x * y)) %>% 
    select(growth)
}
```

Almost identical, here is the second simulation function using `accumulate()`.

```{r}

simulation_accum_2 <- function(init_value, N, mean, stdev) {
  tibble(c(init_value, 1 + rnorm(N, mean, stdev))) %>% 
    `colnames<-`("returns") %>%
  mutate(growth = accumulate(returns, `*`)) %>% 
  select(growth)
}
```

Finally, here is a simulation function using `cumprod()`.

```{r}
simulation_cumprod <- function(init_value, N, mean, stdev) {
  tibble(c(init_value, 1 + rnorm(N, mean, stdev))) %>% 
    `colnames<-`("returns") %>%
  mutate(growth = cumprod(returns)) %>% 
  select(growth)
}
```

Here is a function that uses all three methods, in case we want a fast way to re-confirm consistency. 

```{r}

simulation_confirm_all <- function(init_value, N, mean, stdev) {
  tibble(c(init_value, 1 + rnorm(N, mean, stdev))) %>% 
    `colnames<-`("returns") %>%
    mutate(growth1 = accumulate(returns, function(x, y) x * y),
           growth2 = accumulate(returns, `*`),
           growth3 = cumprod(returns)) %>% 
    select(-returns)
}
```

Let's test that `confirm_all()` function with an init_value of 1, N of 120, and our mean/sd pair

```{r}
simulation_confirm_all_test <- simulation_confirm_all(1, 120, mean_port_return, stddev_port_return)

tail(simulation_confirm_all_test)
```

3 functions, 3 simulations, consistent results.  

Now we are ready to run more than one simulation. 

First, we'll need an object to hold all these simulations. Let's creat an empty matrix with 51 columns, an initial value of 1 and intuitive column names. Why 51 instead of 50? I want the median simulation to have a value that maps to an actual simulation. 

We will use the `rep()` function to create 51 rows with a `1` as the value.

```{r}
sims <- 51
starts <- 
  rep(1, sims) %>%
  set_names(paste("sim", 1:sims, sep = ""))
```

Take a peek at the `starts` object to see what we just created and how it can house our simulations.

```{r}
head(starts)
tail(starts)
```
 This is where we'll store the results of the 51 simulations.
 
Now we want to apply one of our simulation functions (we will go with `simulation_accum_1`) to each of the 51 columns of the `starts` matrix and we will do that using the `map_dfc()` function from the `purrr` package. 

`map_dfc` will take a vector, in this case the row of 1's in the `starts` object and apply a function to it, in this case whichever simulation function we choose.  By appending `_dfc()` to the base `map()` function, we are asking the function to store each of its results as the column of a data frame. After running the code below, we will have a data frame with 51 columns, one for each of our simulations. 

We need to choose how many months to simulate (the N argument to our simulation function) and supply the mean/sd pair as we did before. We don't need to supply the `init_value` argument because the `init_value` is 1, that same 1 which is in the 51 columns. 


```{r}
monte_carlo_sim_51 <- 
  map_dfc(starts, simulation_accum_1, N = 120, mean = mean_port_return, stdev = stddev_port_return)

tail(monte_carlo_sim_51)
```

Have a look at the results. We now have 51 simulations of the growth of a dollar and we simulated that growth over 120 months. 


Let's add one more piece to help with charting. We simulated 120 months so let's add a column, called `month` that is numbered 1 through 120.  We will use `mutate(month = seq(1:nrow(.)))` and then clean up the column names and order. `nrow()` is equal to the number of rows in our object. If we were to change to 130 simulations, that would generate 130 rows, and `nrow()` would be equal to `130.

```{r}
monte_carlo_sim_51 <- 
  map_dfc(starts, simulation_accum_1,
          N = 120, mean = mean_port_return, 
          stdev = stddev_port_return) %>% 
  mutate(month = seq(1:nrow(.))) %>% 
  select(month, everything()) %>% 
  `colnames<-`(c("month", names(starts)))

tail(monte_carlo_sim_51)
```

Now we have 51 columns of simulations and 1 column of months. Note that we have 121 rows because we started with an intitial value of $1, and then simulated returns over 120 months. 

Let's visualize the results with `ggplot()` - the fun part of simulation. We'll start with a chart of all 51 simulations and give different color to each one by setting `ggplot(aes(x = month, y = growth, color = sim))`.  `ggplot()` will automatically generate a legend for all 51 time series but that gets quite crowded. We will suppress the legend with `theme(legend.position = "none")`.

```{r}
monte_carlo_sim_51 %>% 
  gather(sim, growth, -month) %>% 
  group_by(sim) %>% 
  ggplot(aes(x = month, y = growth, color = sim)) + 
  geom_line() +
  theme(legend.position="none")
```


Alright, we see quite a range of returns. Let's check the minimum, maximum and median simulation. We will use the `summarise()` function here.

```{r}

sim_summary <- 
monte_carlo_sim_51 %>% 
  gather(sim, growth, -month) %>% 
  group_by(sim) %>% 
  summarise(final = last(growth)) %>% 
  summarise(
            max = max(final), 
            min = min(final),
            median = median(final))
sim_summary
```

The range is `r sim_summary$max` to `r sim_summary$min`. 

We can clean up our original visualization by including only the max, min and median that were just calculated. 

```{r}

monte_carlo_sim_51 %>% 
  gather(sim, growth, -month) %>% 
  group_by(sim) %>%
  filter(
      any(growth == sim_summary$max) || 
      any(growth == sim_summary$median) ||
      any(growth == sim_summary$min)) %>% 
  ggplot(aes(x = month, y = growth)) + 
  geom_line(aes(color = sim))
```


Since we have a wide range of possible end values, let's examine the quantiles for those values. 

First, we'll assign different probability values to a vector with 
`probs <- c(.005, .025, .25, .5, .75, .975, .995)`

```{r}
probs <- c(.005, .025, .25, .5, .75, .975, .995)
```

Next we want to isolate the end values for our 51 dollar growth simulations. We use `summarise(final = last(growth))` and create a new object called `sim_final_quantile` to hold final values.

```{r}

sim_final_quantile <- 
monte_carlo_sim_51 %>% 
  gather(sim, growth, -month) %>% 
  group_by(sim) %>% 
  summarise(final = last(growth))
```

Finally we call the `quantile()` function on `sim_final_quantile$final` and pass in our vector of probability values, which we labeled `probs`.

```{r}

quantiles <- 
  round(quantile(sim_final_quantile$final, probs = probs), 2) %>% 
  tibble() %>%
  `colnames<-`("value") %>% 
  mutate(probs = probs) %>% 
  spread(probs, value)

quantiles[, 1:6]

```

Our 95% confidence interval for the growth of a dollar is between `r quantiles[,2]` and `r quantiles[,6]`. 

Our .5% super outlier negative result is `r quantiles[,1]`. 


As we said at the beginning, it's fair to quibble or viscerally disagree with the assumptions that underlie this simulation.  


[probably delete this]
```{r}
 
monte_carlo_sim_51 %>% 
  gather(sim, growth, -month) %>% 
  group_by(sim) %>% 
  summarise(final = last(growth)) %>% 
  ggplot(aes(x = final)) +
  geom_histogram(color = "cornflowerblue", fill = "cornflowerblue", binwidth = .05)
```



## Shiny

Now to Shiny wherein a user can build a custom portfolio and then simulate returns out to whatever date that user chooses.

The input sidebar is our usual except we also ask for the number of months to be simulated with 
`numericInput("sim_months", "Months to Sim", 120, min = 6, max = 240, step = 6))`

```{r, eval = FALSE}
fluidRow(
  column(7,
  numericInput("sim_months", "Months to Sim", 120, min = 6, max = 240, step = 6))
)
```

From here, we calculate portfolio returns and save as 
`portfolio_returns_tq_rebalanced_monthly`, and then find the mean and standard deviation of those returns. Those are the parameters we need for the simulation. 

```{r, eval = FALSE}
mean_port_return <- eventReactive(input$go, {
  
  portfolio_returns_tq_rebalanced_monthly <- portfolio_returns_tq_rebalanced_monthly()
  
  mean(portfolio_returns_tq_rebalanced_monthly$returns)
})

stddev_port_return <- eventReactive(input$go, {
  
  portfolio_returns_tq_rebalanced_monthly <- portfolio_returns_tq_rebalanced_monthly()
  
  sd(portfolio_returns_tq_rebalanced_monthly$returns)
})
```

Next we define one of our simulation functions. 

```{r, eval = FALSE}
simulation_accum_1 <- function(init_value, N, mean, stdev) {
    tibble(c(init_value, 1 + rnorm(N, mean, stdev))) %>% 
    `colnames<-`("returns") %>%
    mutate(growth = accumulate(returns, function(x, y) x * y)) %>% 
    select(growth)
}
```

Then, we call `eventReactive()` to run the simulation, following the same logic as we did above. 

```{r, eval = FALSE}
monte_carlo_sim_51 <- eventReactive(input$go, { 
  
  sims <- 51
  
  starts <- 
    rep(1, sims) %>%
    set_names(paste("sim", 1:sims, sep = ""))
  
  map_dfc(starts, simulation_accum_1,
          N = input$sim_months, mean = mean_port_return(), 
          stdev = stddev_port_return()) %>% 
  mutate(month = seq(1:nrow(.))) %>% 
  select(month, everything()) %>% 
  `colnames<-`(c("month", names(starts)))
  
})
```


We now have a reactive object called `monte_carlo_sim_51()` which holds our 51 simulations of the custom portfolio. We can visualize with `ggplot()`, exactly as we did the visualization section. 

```{r, eval = FALSE}
renderPlot(
  monte_carlo_sim_51() %>% 
    gather(sim, growth, -month) %>% 
    group_by(sim) %>% 
    ggplot(aes(x = month, y = growth, color = sim)) + 
    geom_line() +
    theme(legend.position="none") +
    scale_y_continuous(labels = dollar)
)
```

Perhaps our end users want to peek at the actual numbers in the simulations. We can make them available in a table with the following code. 

```{r, eval = FALSE}
renderTable(
  monte_carlo_sim_51()
)

```

And, finally, perhaps we want to chart just the minimum, median and maximum simulation with `ggplot()`.

```{r, eval = FALSE}
renderPlot({
 
sim_summary <- 
  monte_carlo_sim_51() %>% 
  gather(sim, growth, -month) %>% 
  group_by(sim) %>% 
  summarise(final = last(growth)) %>% 
  summarise(
            max = max(final), 
            min = min(final),
            median = median(final))

monte_carlo_sim_51() %>% 
  gather(sim, growth, -month) %>% 
  group_by(sim) %>%
  filter(
      any(growth == sim_summary$max) || 
      any(growth == sim_summary$median) ||
      any(growth == sim_summary$min)) %>% 
  ggplot(aes(x = month, y = growth)) + 
  geom_line(aes(color = sim)) + 
  scale_y_continuous(labels = dollar)

})
```

